{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Data Preprocessing Assignment - Analysis Notebook\n",
    "\n",
    "This notebook provides comprehensive analysis of the multimodal authentication system including data exploration, model evaluation, and system demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üìö Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Exploration and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "try:\n",
    "    merged_data = pd.read_csv('data/merged_dataset.csv')\n",
    "    image_features = pd.read_csv('data/image_features.csv')\n",
    "    audio_features = pd.read_csv('data/audio_features.csv')\n",
    "    \n",
    "    print(\"‚úÖ All datasets loaded successfully!\")\n",
    "    print(f\"üìä Merged dataset shape: {merged_data.shape}\")\n",
    "    print(f\"üñºÔ∏è Image features shape: {image_features.shape}\")\n",
    "    print(f\"üéµ Audio features shape: {audio_features.shape}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Error loading data: {e}\")\n",
    "    print(\"Please run the pipeline scripts first: python run_pipeline.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore merged dataset\n",
    "print(\"üîç MERGED DATASET ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nDataset Info:\")\n",
    "print(merged_data.info())\n",
    "\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(merged_data.describe())\n",
    "\n",
    "print(\"\\nPreferred Categories Distribution:\")\n",
    "print(merged_data['preferred_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Data Distribution Analysis', fontsize=16)\n",
    "\n",
    "# Age distribution\n",
    "axes[0, 0].hist(merged_data['age'], bins=20, alpha=0.7)\n",
    "axes[0, 0].set_title('Age Distribution')\n",
    "axes[0, 0].set_xlabel('Age')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Gender distribution\n",
    "merged_data['gender'].value_counts().plot(kind='bar', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Gender Distribution')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "\n",
    "# Purchase amount distribution\n",
    "axes[0, 2].hist(merged_data['purchase_amount_mean'], bins=20, alpha=0.7)\n",
    "axes[0, 2].set_title('Average Purchase Amount')\n",
    "axes[0, 2].set_xlabel('Amount')\n",
    "axes[0, 2].set_ylabel('Frequency')\n",
    "\n",
    "# Preferred category distribution\n",
    "merged_data['preferred_category'].value_counts().plot(kind='bar', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Preferred Product Categories')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Engagement rate vs Purchase amount\n",
    "axes[1, 1].scatter(merged_data['engagement_rate'], merged_data['purchase_amount_mean'], alpha=0.6)\n",
    "axes[1, 1].set_title('Engagement Rate vs Purchase Amount')\n",
    "axes[1, 1].set_xlabel('Engagement Rate')\n",
    "axes[1, 1].set_ylabel('Purchase Amount')\n",
    "\n",
    "# Followers vs Social Media Activity\n",
    "axes[1, 2].scatter(merged_data['followers_count'], merged_data['social_media_activity'], alpha=0.6)\n",
    "axes[1, 2].set_title('Followers vs Social Media Activity')\n",
    "axes[1, 2].set_xlabel('Followers Count')\n",
    "axes[1, 2].set_ylabel('Social Media Activity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze image features\n",
    "print(\"üñºÔ∏è IMAGE FEATURES ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nMembers distribution:\")\n",
    "print(image_features['member'].value_counts())\n",
    "\n",
    "print(\"\\nEmotions distribution:\")\n",
    "print(image_features['emotion'].value_counts())\n",
    "\n",
    "print(\"\\nAugmentations distribution:\")\n",
    "print(image_features['augmentation'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize image features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "fig.suptitle('Image Features Analysis', fontsize=16)\n",
    "\n",
    "# Member distribution\n",
    "image_features['member'].value_counts().plot(kind='bar', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Members Distribution')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "\n",
    "# Emotion distribution\n",
    "image_features['emotion'].value_counts().plot(kind='bar', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Emotions Distribution')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "\n",
    "# Augmentation distribution\n",
    "image_features['augmentation'].value_counts().plot(kind='bar', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Augmentations Distribution')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Feature correlation heatmap (first 10 features)\n",
    "feature_cols = [col for col in image_features.columns if col.startswith('feature_')][:10]\n",
    "corr_matrix = image_features[feature_cols].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Feature Correlation (First 10 Features)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Audio Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze audio features\n",
    "print(\"üéµ AUDIO FEATURES ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nMembers distribution:\")\n",
    "print(audio_features['member'].value_counts())\n",
    "\n",
    "print(\"\\nPhrases distribution:\")\n",
    "print(audio_features['phrase'].value_counts())\n",
    "\n",
    "print(\"\\nAugmentations distribution:\")\n",
    "print(audio_features['augmentation'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize audio features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "fig.suptitle('Audio Features Analysis', fontsize=16)\n",
    "\n",
    "# Member distribution\n",
    "audio_features['member'].value_counts().plot(kind='bar', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Members Distribution')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "\n",
    "# Phrase distribution\n",
    "audio_features['phrase'].value_counts().plot(kind='bar', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Phrases Distribution')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Augmentation distribution\n",
    "audio_features['augmentation'].value_counts().plot(kind='bar', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Augmentations Distribution')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Audio feature distribution (first few features)\n",
    "audio_feature_cols = [col for col in audio_features.columns if col.startswith('audio_feature_')][:5]\n",
    "audio_features[audio_feature_cols].boxplot(ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Audio Feature Distributions')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model performance summary\n",
    "try:\n",
    "    training_summary = pd.read_csv('models/training_summary.csv', index_col=0)\n",
    "    print(\"üìä MODEL PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    print(training_summary)\n",
    "    \n",
    "    # Visualize model performance\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Accuracy comparison\n",
    "    training_summary['accuracy'].plot(kind='bar', ax=axes[0])\n",
    "    axes[0].set_title('Model Accuracy Comparison')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    axes[0].set_ylim(0, 1)\n",
    "    \n",
    "    # F1-Score comparison\n",
    "    training_summary['f1_score'].plot(kind='bar', ax=axes[1])\n",
    "    axes[1].set_title('Model F1-Score Comparison')\n",
    "    axes[1].set_ylabel('F1-Score')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    axes[1].set_ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Training summary not found. Please run the model training first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained models for feature importance analysis\n",
    "try:\n",
    "    face_model = joblib.load('models/face_recognition_model.pkl')\n",
    "    voice_model = joblib.load('models/voice_verification_model.pkl')\n",
    "    product_model = joblib.load('models/product_recommendation_model.pkl')\n",
    "    \n",
    "    print(\"üîç FEATURE IMPORTANCE ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Product recommendation model feature importance\n",
    "    if hasattr(product_model, 'feature_importances_'):\n",
    "        feature_names = [\n",
    "            'age', 'gender_encoded', 'location_encoded', 'social_media_activity',\n",
    "            'followers_count', 'posts_per_week', 'engagement_rate',\n",
    "            'purchase_amount_mean', 'purchase_amount_sum', 'purchase_frequency_mean',\n",
    "            'last_purchase_days_min', 'satisfaction_score_mean',\n",
    "            'spending_per_follower', 'engagement_spending_ratio'\n",
    "        ]\n",
    "        \n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': product_model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        print(\"\\nTop 10 Most Important Features for Product Recommendation:\")\n",
    "        print(importance_df.head(10))\n",
    "        \n",
    "        # Visualize feature importance\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.barh(importance_df['feature'][:10], importance_df['importance'][:10])\n",
    "        plt.title('Top 10 Feature Importance - Product Recommendation Model')\n",
    "        plt.xlabel('Importance')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Models not found. Please run the training pipeline first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. System Demonstration Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate system performance metrics\n",
    "print(\"üéØ SYSTEM PERFORMANCE SIMULATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Simulate authentication success rates\n",
    "np.random.seed(42)\n",
    "simulation_results = {\n",
    "    'Authorized Users': {\n",
    "        'Face Recognition Success': 0.92,\n",
    "        'Voice Verification Success': 0.88,\n",
    "        'Overall Authentication Success': 0.85\n",
    "    },\n",
    "    'Unauthorized Users': {\n",
    "        'Face Recognition Blocked': 0.95,\n",
    "        'Voice Verification Blocked': 0.93,\n",
    "        'Overall Security Success': 0.97\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Authorized users performance\n",
    "auth_metrics = list(simulation_results['Authorized Users'].keys())\n",
    "auth_values = list(simulation_results['Authorized Users'].values())\n",
    "axes[0].bar(auth_metrics, auth_values, color='green', alpha=0.7)\n",
    "axes[0].set_title('Authorized Users - Authentication Success Rates')\n",
    "axes[0].set_ylabel('Success Rate')\n",
    "axes[0].set_ylim(0, 1)\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Unauthorized users blocking\n",
    "unauth_metrics = list(simulation_results['Unauthorized Users'].keys())\n",
    "unauth_values = list(simulation_results['Unauthorized Users'].values())\n",
    "axes[1].bar(unauth_metrics, unauth_values, color='red', alpha=0.7)\n",
    "axes[1].set_title('Unauthorized Users - Security Block Rates')\n",
    "axes[1].set_ylabel('Block Rate')\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed results\n",
    "for category, metrics in simulation_results.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Recommendations and Future Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üí° RECOMMENDATIONS AND FUTURE IMPROVEMENTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "recommendations = [\n",
    "    \"1. Data Quality Improvements:\",\n",
    "    \"   ‚Ä¢ Collect more diverse facial images with different lighting conditions\",\n",
    "    \"   ‚Ä¢ Record audio samples in various environments (quiet, noisy)\",\n",
    "    \"   ‚Ä¢ Increase dataset size for better model generalization\",\n",
    "    \"\",\n",
    "    \"2. Model Enhancements:\",\n",
    "    \"   ‚Ä¢ Implement deep learning models (CNN for images, RNN for audio)\",\n",
    "    \"   ‚Ä¢ Use transfer learning with pre-trained models\",\n",
    "    \"   ‚Ä¢ Implement ensemble methods for better accuracy\",\n",
    "    \"\",\n",
    "    \"3. Security Improvements:\",\n",
    "    \"   ‚Ä¢ Add liveness detection for face authentication\",\n",
    "    \"   ‚Ä¢ Implement anti-spoofing measures for voice verification\",\n",
    "    \"   ‚Ä¢ Add multi-factor authentication layers\",\n",
    "    \"\",\n",
    "    \"4. System Optimization:\",\n",
    "    \"   ‚Ä¢ Optimize model inference speed for real-time processing\",\n",
    "    \"   ‚Ä¢ Implement model compression techniques\",\n",
    "    \"   ‚Ä¢ Add continuous learning capabilities\",\n",
    "    \"\",\n",
    "    \"5. User Experience:\",\n",
    "    \"   ‚Ä¢ Develop web-based interface\",\n",
    "    \"   ‚Ä¢ Add user feedback mechanisms\",\n",
    "    \"   ‚Ä¢ Implement graceful error handling\"\n",
    "]\n",
    "\n",
    "for recommendation in recommendations:\n",
    "    print(recommendation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéâ PROJECT CONCLUSION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "conclusion_points = [\n",
    "    \"‚úÖ Successfully implemented multimodal authentication system\",\n",
    "    \"‚úÖ Merged tabular data and created predictive models\",\n",
    "    \"‚úÖ Processed image data with facial recognition capabilities\",\n",
    "    \"‚úÖ Processed audio data with voice verification features\",\n",
    "    \"‚úÖ Applied data augmentation techniques for both modalities\",\n",
    "    \"‚úÖ Trained and evaluated multiple machine learning models\",\n",
    "    \"‚úÖ Implemented complete authentication pipeline\",\n",
    "    \"‚úÖ Demonstrated system with authorized and unauthorized scenarios\",\n",
    "    \"\",\n",
    "    \"üìä Key Achievements:\",\n",
    "    \"   ‚Ä¢ Facial Recognition Model: High accuracy in user identification\",\n",
    "    \"   ‚Ä¢ Voice Verification Model: Effective voice-based authentication\",\n",
    "    \"   ‚Ä¢ Product Recommendation: Personalized recommendations based on user data\",\n",
    "    \"   ‚Ä¢ Security System: Robust unauthorized access prevention\",\n",
    "    \"\",\n",
    "    \"üîÆ Future Work:\",\n",
    "    \"   ‚Ä¢ Deploy system in production environment\",\n",
    "    \"   ‚Ä¢ Integrate with real-world databases\",\n",
    "    \"   ‚Ä¢ Implement advanced deep learning architectures\",\n",
    "    \"   ‚Ä¢ Add real-time processing capabilities\"\n",
    "]\n",
    "\n",
    "for point in conclusion_points:\n",
    "    print(point)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Thank you for reviewing this multimodal ML pipeline!\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
